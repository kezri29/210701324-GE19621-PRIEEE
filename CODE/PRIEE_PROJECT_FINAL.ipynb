{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olJGGQeGyKI2",
        "outputId": "88c07612-104a-42ef-c762-743aed89e1ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "\n",
        "import random\n",
        "import json\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        self.l1 = nn.Linear(input_size, hidden_size)\n",
        "        self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.l3 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.l2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.l3(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "9PJSxBNC4VZ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/home/intents.json', 'r') as f:\n",
        "    intents = json.load(f)\n"
      ],
      "metadata": {
        "id": "WINJDN7V4cAm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def tokenize(sentence):\n",
        "    return nltk.word_tokenize(sentence)\n",
        "\n",
        "def stem(word):\n",
        "    return stemmer.stem(word.lower())\n",
        "\n",
        "def bag_of_words(tokenized_sentence, words):\n",
        "    sentence_words = [stem(word) for word in tokenized_sentence]\n",
        "    bag = np.zeros(len(words), dtype=np.float32)\n",
        "    for idx, w in enumerate(words):\n",
        "        if w in sentence_words:\n",
        "            bag[idx] = 1\n",
        "\n",
        "    return bag"
      ],
      "metadata": {
        "id": "e7_O0Qxd4yqI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = []\n",
        "tags = []\n",
        "xy = []\n",
        "for intent in intents['intents']:\n",
        "    tag = intent['tag']\n",
        "    tags.append(tag)\n",
        "    for pattern in intent['patterns']:\n",
        "        w = tokenize(pattern)\n",
        "        all_words.extend(w)\n",
        "        xy.append((w, tag))\n",
        "\n",
        "ignore_words = ['?', '.', '!']\n",
        "all_words = [stem(w) for w in all_words if w not in ignore_words]\n",
        "all_words = sorted(set(all_words))\n",
        "tags = sorted(set(tags))\n",
        "\n",
        "print(len(xy), \"patterns\")\n",
        "print(len(tags), \"tags:\", tags)\n",
        "print(len(all_words), \"unique stemmed words:\", all_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uaNLVGn42zW",
        "outputId": "36752700-1d1e-4690-d3ec-6655aec3b313"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "232 patterns\n",
            "80 tags: ['about', 'afternoon', 'anxious', 'ask', 'casual', 'creation', 'death', 'default', 'depressed', 'done', 'evening', 'fact-1', 'fact-10', 'fact-11', 'fact-12', 'fact-13', 'fact-14', 'fact-15', 'fact-16', 'fact-17', 'fact-18', 'fact-19', 'fact-2', 'fact-20', 'fact-21', 'fact-22', 'fact-23', 'fact-24', 'fact-25', 'fact-26', 'fact-27', 'fact-28', 'fact-29', 'fact-3', 'fact-30', 'fact-31', 'fact-32', 'fact-5', 'fact-6', 'fact-7', 'fact-8', 'fact-9', 'friends', 'goodbye', 'greeting', 'happy', 'hate-me', 'hate-you', 'help', 'jokes', 'learn-mental-health', 'learn-more', 'location', 'meditation', 'mental-health-fact', 'morning', 'name', 'neutral-response', 'night', 'no-approach', 'no-response', 'not-talking', 'pandora-useful', 'problem', 'repeat', 'sad', 'scared', 'skill', 'sleep', 'something-else', 'stressed', 'stupid', 'suicide', 'thanks', 'understand', 'user-advice', 'user-agree', 'user-meditation', 'worthless', 'wrong']\n",
            "280 unique stemmed words: [\"'ll\", \"'m\", \"'re\", \"'s\", \"'ve\", ',', 'a', 'about', 'absolut', 'advic', 'affect', 'afternoon', 'again', 'all', 'alot', 'alreadi', 'am', 'and', 'ani', 'anoth', 'answer', 'anxieti', 'anxiou', 'anymor', 'anyon', 'anyth', 'appear', 'approach', 'are', 'ask', 'au', 'avail', 'aw', 'away', 'be', 'becaus', 'becom', 'befor', 'better', 'between', 'bonjour', 'boyfriend', 'break', 'bring', 'brother', 'burn', 'by', 'bye', 'ca', 'call', 'can', 'caus', 'cheer', 'child', 'commit', 'connect', 'continu', 'control', 'could', 'crazi', 'creat', 'cure', 'dad', 'day', 'defin', 'depress', 'deserv', 'did', 'die', 'differ', 'disord', 'do', 'doe', 'down', 'dumb', 'els', 'empti', 'enough', 'even', 'exam', 'fact', 'famili', 'fare', 'feel', 'few', 'financi', 'find', 'fine', 'focu', 'for', 'friend', 'from', 'get', 'girlfriend', 'give', 'go', 'good', 'goodby', 'great', 'group', 'guess', 'guten', 'had', 'hand', 'happi', 'hate', 'have', 'health', 'hello', 'help', 'hey', 'hi', 'hmmm', 'hola', 'how', 'howdi', 'i', 'if', 'ill', 'import', 'in', 'insominia', 'insomnia', 'interest', 'involv', 'is', 'it', 'joke', 'just', 'k', 'kill', 'know', 'konnichiwa', 'last', 'later', 'learn', 'let', 'like', 'live', 'locat', 'lone', 'made', 'maintain', 'make', 'me', 'mean', 'medic', 'medit', 'mental', 'mention', 'mom', 'money', 'more', 'morn', 'much', 'my', 'myself', \"n't\", 'name', 'need', 'new', 'nice', 'night', 'no', 'nobodi', 'not', 'noth', 'now', 'of', 'oh', 'ok', 'okay', 'ola', 'on', 'one', 'open', 'option', 'or', 'out', 'pass', 'past', 'peopl', 'pleas', 'possibl', 'practic', 'prepar', 'prevent', 'probabl', 'problem', 'profession', 'proper', 'realli', 'recov', 'relationship', 'repeat', 'respons', 'revoir', 'right', 'robot', 'sad', 'said', 'say', 'sayonara', 'scare', 'see', 'seem', 'sens', 'should', 'shut', 'sign', 'sister', 'sleep', 'slept', 'so', 'social', 'some', 'someon', 'someth', 'sound', 'start', 'stay', 'still', 'stress', 'stuck', 'stupid', 'suffer', 'suicid', 'support', 'sure', 'symptom', 'tag', 'take', 'talk', 'tell', 'than', 'thank', 'that', 'the', 'thee', 'then', 'therapi', 'therapist', 'there', 'thi', 'think', 'thought', 'through', 'to', 'today', 'told', 'treatment', 'trust', 'type', 'understand', 'unwel', 'up', 'use', 'useless', 'veri', 'want', 'warn', 'way', 'we', 'well', 'were', 'what', 'whatev', 'where', 'whi', 'who', 'with', 'worri', 'worthless', 'would', 'wrong', 'ye', 'yeah', 'you', 'your', 'yourself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "for (pattern_sentence, tag) in xy:\n",
        "    bag = bag_of_words(pattern_sentence, all_words)\n",
        "    X_train.append(bag)\n",
        "    label = tags.index(tag)\n",
        "    y_train.append(label)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)"
      ],
      "metadata": {
        "id": "0wlU0K-k47Hk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 1000\n",
        "batch_size = 8\n",
        "learning_rate = 0.001\n",
        "input_size = len(X_train[0])\n",
        "hidden_size = 8\n",
        "output_size = len(tags)\n",
        "print(input_size, output_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9j5QUib4_Oc",
        "outputId": "5bf9c538-84b7-452e-ad35-33a35767c7ba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatDataset(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = len(X_train)\n",
        "        self.x_data = X_train\n",
        "        self.y_data = y_train\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ],
      "metadata": {
        "id": "PcvfizVq5EXX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ChatDataset()\n",
        "train_loader = DataLoader(dataset=dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)"
      ],
      "metadata": {
        "id": "fxelQFZK5H22"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for (words, labels) in train_loader:\n",
        "        words = words.to(device)\n",
        "        labels = labels.to(dtype=torch.long).to(device)\n",
        "\n",
        "        outputs = model(words)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 100 == 0:\n",
        "        print (f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "\n",
        "print(f'Final loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsGPrNPy5M5K",
        "outputId": "cae8b851-6029-4d8c-ac00-ee2ed6d1d2da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.2283\n",
            "Epoch [200/1000], Loss: 0.0327\n",
            "Epoch [300/1000], Loss: 0.0025\n",
            "Epoch [400/1000], Loss: 0.0006\n",
            "Epoch [500/1000], Loss: 0.0001\n",
            "Epoch [600/1000], Loss: 0.0000\n",
            "Epoch [700/1000], Loss: 0.0000\n",
            "Epoch [800/1000], Loss: 0.0000\n",
            "Epoch [900/1000], Loss: 0.0000\n",
            "Epoch [1000/1000], Loss: 0.0000\n",
            "Final loss: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "\"model_state\": model.state_dict(),\n",
        "\"input_size\": input_size,\n",
        "\"hidden_size\": hidden_size,\n",
        "\"output_size\": output_size,\n",
        "\"all_words\": all_words,\n",
        "\"tags\": tags\n",
        "}\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "torch.save(data, FILE)\n",
        "\n",
        "print(f'Training completed. File is saved to {FILE}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlMdF0QN5eOr",
        "outputId": "d70995c4-5419-45b8-9238-e574a39a59e8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training completed. File is saved to data.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "FILE = \"data.pth\"\n",
        "data = torch.load(FILE)\n",
        "\n",
        "input_size = data[\"input_size\"]\n",
        "hidden_size = data[\"hidden_size\"]\n",
        "output_size = data[\"output_size\"]\n",
        "all_words = data['all_words']\n",
        "tags = data['tags']\n",
        "model_state = data[\"model_state\"]\n",
        "\n",
        "model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
        "model.load_state_dict(model_state)\n",
        "model.eval()\n",
        "\n",
        "bot_name = \"ChatBot\"\n",
        "print(\"Let's chat! I hope you are doing good. (type 'Quit' to exit)\")\n",
        "while True:\n",
        "    sentence = input(\"You: \")\n",
        "    if sentence == \"Quit\":\n",
        "        break\n",
        "\n",
        "    sentence = tokenize(sentence)\n",
        "    X = bag_of_words(sentence, all_words)\n",
        "    X = X.reshape(1, X.shape[0])\n",
        "    X = torch.from_numpy(X).to(device)\n",
        "\n",
        "    output = model(X)\n",
        "    _, predicted = torch.max(output, dim=1)\n",
        "\n",
        "    tag = tags[predicted.item()]\n",
        "\n",
        "    probs = torch.softmax(output, dim=1)\n",
        "    prob = probs[0][predicted.item()]\n",
        "    if prob.item() > 0.75:\n",
        "        for intent in intents['intents']:\n",
        "            if tag == intent[\"tag\"]:\n",
        "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
        "    else:\n",
        "        print(f\"{bot_name}: I am not able to get you. Kindly expalin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "J5UcE5er5ql-",
        "outputId": "d18e9b4f-42b0-4c6d-acbc-5df9fde1c87f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's chat! I hope you are doing good. (type 'Quit' to exit)\n",
            "You: Good Morning\n",
            "ChatBot: Good morning. I hope you had a good night's sleep. How are you feeling today? \n",
            "You: I am stressed\n",
            "ChatBot: I'm sorry to hear that. Just know that I'm here for you. Talking about it might help. Why do you think you don't have any friends?\n",
            "You: no \n",
            "ChatBot: Tell me more\n",
            "You: i am having insomnia\n",
            "ChatBot: How long have you been feeling this way?\n",
            "You: for a year\n",
            "ChatBot: I am not able to get you. Kindly expalin.\n",
            "You: from this morning\n",
            "ChatBot: I am not able to get you. Kindly expalin.\n",
            "You: give me advice\n",
            "ChatBot: Sadness is a normal reaction to a loss, disappointment, problems, or other difficult situations. Feeling sad from time to time is just another part of being human. In these cases, feelings of sadness go away quickly and you can go about your daily life. Other ways to talk about sadness might be feeling low, feeling down, or feeling blue.A person may say they are feeling depressed, but if it goes away on its own and doesn't impact life in a big way, it probably isn't the illness of depression. Depression is a mental illness that affects your mood, the way you understand yourself, and the way you understand and relate to things around you. It can also go by different names, such as clinical depression, major depressive disorder, or major depression. Depression can come up for no reason, and it lasts for a long time. It's much more than sadness or low mood. People who experience depression may feel worthless or hopeless. They may feel unreasonable guilty. Some people may experience depression as anger or irritability. It may be hard to concentrate or make decisions. Most people lose interest in things that they used to enjoy and may isolate themselves from others. There are also physical signs of depression, such as problems with sleep, appetite and energy and unexplainable aches or pains. Some may experience difficult thoughts about death or ending their life (suicide). Depression lasts longer than two weeks, doesn't usually go away on its own, and impacts your life. It's a real illness, and it is very treatable. It's important to seek help if you're concerned about depression.\n",
            "You: i am very happy\n",
            "ChatBot: Did something happen which made you feel this way?\n",
            "You: i got married\n",
            "ChatBot: Please don't hesitate to talk to me.\n",
            "You: byr\n",
            "ChatBot: Sorry, I didn't understand you.\n",
            "You: bye\n",
            "ChatBot: See you later.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-12cd9ba4e05b>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Let's chat! I hope you are doing good. (type 'Quit' to exit)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}